---
title: "HW 4"
author: "Andrew Jowe"
---

```{r setup, echo=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

# 1
a. The errors seem to be normally distributed because the dots on the QQ plot are close to the QQ line.
b. There seems to be outliers because there are dots that are more than 5 errors away from the fitted mean on the errors vs means plot.
c. It appears that the groups don't have equal variances because the vertical spread of the dots are not the same for all fitted means on the errors vs fitted means plot.
d. I would not remove any observations because the sample size for each group is already pretty small. More data means that our estimates are more accurate.

# 2
a. Since the p-value is typically greater than $\alpha$ (at most $0.1$), we fail to reject the null hypothesis. Therefore, the data follows a normal distribution.
b. Since the p-value is typically greater than $\alpha$ (at most $0.1$), we fail to reject the null hypothesis. Therefore, the variances of each group are approximately equal.
c. I would not suggest transforming the data because our data already fits the ANOVA assumptions.
d. Our confidence intervals and p-values are likely to be reliable because we know the ANOVA assumptions hold.

# 3
a. It appears that the ANOVA assumptions are not met, because the graphs suggest that the data may not have equal variances between groups, and we cannot say for sure if the data follows a normal distribution. The Errors vs Group Means graph has different spreads for all group means, suggesting non-equal variances. The dots on the normal QQ plot do not follow the QQ line for the points beyond the $\pm 1$ theoretical quantiles, suggesting that the data may not be normally distributed. However, the histogram of errors show that the data is approximately normal. In the best case scenario, we need to remove outliers so that the data follows a normal distribution.
b. The null hypothesis for the Shapiro-Wilks test is that the data follows a normal distribution. The alternative hypothesis is that the data does not follow a normal distribution.
c. The null hypothesis for the Brown-Forstyhe test is that the groups all have equal variances. The alternative hypothesis is that the groups do not all have equal variances (at least one of the variances are not equal).
d. No, because we are not sure if the ANOVA assumptions hold.

# 4
a. We have a 0.0734 chance of a type I error, where we reject the null hypothesis when the null hypothesis is true. In other words, this is the chance of stating that the data is not normal when it actually is.
b. We have a 0.0000304 chance of a type I error, where we reject the null hypothesis when the null hypothesis is true. In other words, this is the chance of stating that at least one of the variances are not equal when all groups actually have equal variances.
c. We would suggest transforming the variables because we conclude the variances are not equal between all groups as we will probably reject the null hypothesis of the Brown Forsythe test using typical $\alpha$ values.
d. One downside is that it can make the interpretation of the data more complex. When we interpret, now we have to account for the function we used to transform the data.

# 5
a. Yes, because the dots on the QQ plot are a lot closer to the line compared to before.
b. It has improved, but still not good enough. Although the p-value for the Shapiro Wilks test is a lot higher than before, making it more likely that we would fail to reject the null hypothesis or accept that the data is normally distributed, the Brown Forsythe test did not improve that much as it's p-value is still lower than 0.01. We will most likely still reject the null hypothesis for that test given typical $\alpha$ values, concluding that the groups do not all have equal variances, violating our ANOVA assumptions.
c. Yes, it appears that the groups have constant variances as the spreads for the different group means are around the same on the Errors vs Group Means chart.
d. It has improved, but still not good enough. Although the p-value for the Brown Forsythe test is a lot higher than before, making it more likely that we would fail to reject the null hypothesis or accept that the data is normally distributed, the Shapiro Wilks test did not improve that much as it's p-value is still lower than 0.01. We will most likely still reject the null hypothesis for that test given typical $\alpha$ values, concluding that the data is not normally distributed, violating our ANOVA assumptions.
e. None of the datasets are suitable because all of them violate ANOVA assumptions.

# 6
a. $Y_{ijk} = \mu_{..} + \gamma_i + \delta_j + \epsilon_{ijk}$
<br> With $\sum \gamma_i = 0, \sum \delta_j = 0$
<br> The assumptions and constraints are:
    i. The ANOVA assumptions hold, that is:
        - All $Y_{ijk}$ were randomly sampled
        - The $i$ groups are independent of each other
        - The $j$ groups are independent of each other
        - $\epsilon_{ijk} \sim N(0, \sigma_\epsilon^2)$
    ii. Observations should be independent between groups as a constraint since there is no factor effect between groups in our model.
b. $Y_{ijk} = \mu_{..} + \gamma_i + \delta_j + (\gamma\delta)_{ij} + \epsilon_{ijk}$
<br> With $\sum \gamma_i = 0, \sum \delta_j = 0, \sum \sum (\gamma\delta)_{ij} = 0$
<br> The assumptions are:
    i. The ANOVA assumptions hold, that is:
        - All $Y_{ijk}$ were randomly sampled
        - The $i$ groups are independent of each other
        - The $j$ groups are independent of each other
        - $\epsilon_{ijk} \sim N(0, \sigma_\epsilon^2)$
    ii. Observations can be dependent between groups since there is a factor effect between groups in our model.
    iii. Assumption specific to factor effect between groups: $(\gamma\delta)_{ij} = \mu_{ij} + \gamma_i + \delta_j - \mu_{..}$
c. There seems to be a significant effect of smoking cigarettes on sleep, because there is a change in sleep when we change this factor. The average sleep in hours for those who smoke is $5.90$ compared to $7.04$ for those who don't smoke.
d. There seems to be a significant effect of smoking marijuana on sleep, because there is a change in sleep when we change this factor. The average sleep in hours for those who smoke is $6.71$ compared to $7.073$ for those who don't.
e. There seems to be an interaction effect between smoking cigarettes and smoking marijuana on sleep. For those who don't smoke cigarettes, smoking marijuana decreases the average sleep by $0.18$ hours. However, for those who do smoke cigarettes, smoking marijuana increases the average sleep by $0.97$.

# 7
a. We need two values of $\gamma_i$ to estimate since there are two possibilities for smoking cigarettes.
b. We need two values of $\delta_j$ to estimate since there are two possibilities for smoking marijuana.
c. We need four values of $(\gamma\delta)_{ij}$ to estimate since there are two possibilities for smoking cigarettes multiplied by two possibilities for smoking marijuana.
d. In total, we have $(a - 1) + (b - 1) + 1$ parameters to estimate. In our model $Y_{ijk} = \mu_{..} + \gamma_i + \delta_j + \epsilon_{ijk}$, we have 1 parameter to estimate for $\mu_{..}$, $a - 1$ parameters to estimate for $\gamma_i$, and $b - 1$ parameters to estimate for $\delta_j$.
e. In total, we have $(a - 1) + (b - 1) + (a - 1)(b - 1) + 1$ parameters to estimate. In our model $Y_{ijk} = \mu_{..} + \gamma_i + \delta_j + (\gamma\delta)_{ij} + \epsilon_{ijk}$, we have 1 parameter to estimate for $\mu_{..}$, $a - 1$ parameters to estimate for $\gamma_i$, $(a - 1)(b - 1)$ parameters to estimate for $(\gamma\delta)_{ij}$, and $b - 1$ parameters to estimate for $\delta_j$. If we simplify our result:
<br> $(a - 1) + (b - 1) + (a - 1)(b - 1) + 1$
<br> $\to a - 1 + b - 1 + a * b - a - b + 1 + 1$
<br> $\to a + b + a * b - a - b$
<br> $\to a * b$
<br> $\therefore$ We have $a * b$ total parameters.

# 8
a. False. Our null hypothesis for this test is that the data is normal. A smaller p-value makes it less likely for us to accept the null hypothesis, making it more likely that the data is not normally distributed.
b. False. It is possible for the normality assumption to hold, but $i$ groups have difference variances.
c. True. This matches our answer in 7d.
d. False. This does not match our answer in 7e.

```{r label="Setup R Code", include = FALSE}
# Load data
cancer <- read.csv("Cancer.csv")
trap <- read.csv("Trap.csv")
rat <- read.csv("rat.csv")

# Load libraries
library(car)
library(EnvStats)
```

```{r label="Find Means Function"}
find.means <- function(the.data, fun.name = mean) {
  a = length(unique(the.data[,2]))
  b = length(unique(the.data[,3]))
  means.A = by(the.data[,1], the.data[,2], fun.name)
  means.B = by(the.data[,1],the.data[,3],fun.name)
  means.AB = by(the.data[,1],list(the.data[,2],the.data[,3]),fun.name)
  MAB = matrix(means.AB,nrow = b, ncol = a, byrow = TRUE)
  colnames(MAB) = names(means.A)
  rownames(MAB) = names(means.B)
  MA = as.numeric(means.A)
  names(MA) = names(means.A)
  MB = as.numeric(means.B)
  names(MB) = names(means.B)
  results = list(A = MA, B = MB, AB = MAB)
  return(results)
}
```

# I
a. In the Normal Q-Q plot, the dots beyond $\pm 1$ theoretical quantiles do not conform to the normal line. The graph suggests that the data is not normally distributed, violating our ANOVA assumptions.
```{r I-a}
# Do model
the.model <- lm(Survival ~ Organ, data = cancer)

# Normal Q-Q plot
qqnorm(the.model$residuals)
qqline(the.model$residuals)

# Error vs. Group Means
plot(the.model$fitted.values, the.model$residuals,
     main = "Errors vs. Group Means",
     xlab = "Group Means", ylab = "Errors")
abline(h = 0, col = "purple")
```
b. Here are the new plots:

```{r I-b}
the.model <- lm(Survival ~ Organ, data = cancer)
cancer$ei = the.model$residuals

nt = nrow(cancer) #Calculates the total sample size
a = length(unique(cancer$Organ)) #Calculates the value of a
SSE = sum(cancer$ei^2) #Sums and squares the errors (finds SSE)
MSE = SSE/(nt-a) #Finds MSE
eij.star = the.model$residuals/sqrt(MSE)

alpha = 0.01

# original code
t.cutoff = qt(1 - alpha / (2 * nt), nt - a)

# modified code
t.cutoff = qt(1-alpha, nt-a)

CO.eij = which(abs(eij.star) > t.cutoff)
n_outliers <- length(CO.eij)

outliers <- CO.eij

new.data <- cancer[-CO.eij, ]
new.model <- lm(Survival ~ Organ, data = new.data)

# Normal Q-Q Plot
qqnorm(new.model$residuals)
qqline(new.model$residuals)

# Error vs. Group Means
plot(new.model$fitted.values, new.model$residuals,
     main = "Errors vs. Group Means",
     xlab = "Group Means", ylab = "Errors")
abline(h = 0, col = "purple")
```
```{r I-c}
ei = new.model$residuals
the.SWtest = shapiro.test(ei)
the.p.value <- the.SWtest$p.value
```
c. $p = `r round(the.p.value, 4)`$
```{r I-d, include=FALSE}
the.BFtest = leveneTest(ei~ Organ, data=new.data, center=median)
the.p.value = the.BFtest[[3]][1]
```
d. $p = `r round(the.p.value, 4)`$
```{r I-e}
portion.of.data.removed <- n_outliers / nt
```
e. $`r round(portion.of.data.removed * 100, 2)`\%$ of the data was removed.

# II
```{r II-a}
# Find best lambda
L2 = boxcox(the.model, objective.name = "Shapiro-Wilk", optimize = TRUE)$lambda
```
a. $\lambda = `r round(L2, 4)`$
b. It appears that the tranformations has helped. The dots on the Q-Q plot are close to the Q-Q line, suggesting that the data is normally distributed. On the Error vs. Means plot, the error spread for the different group means are around the same, suggesting that the variances are approximately the same.
```{r II-b}
YT = (cancer$Survival^(L2)-1)/L2
t.data = data.frame(Survival = YT, Organ = cancer$Organ)
t.model = lm(Survival ~ Organ,data = t.data)

# Do model
the.model <- lm(Survival ~ Organ, data = t.data)

# Normal Q-Q plot
qqnorm(the.model$residuals)
qqline(the.model$residuals)

# Error vs. Group Means
plot(the.model$fitted.values, the.model$residuals,
     main = "Errors vs. Group Means",
     xlab = "Group Means", ylab = "Errors")
abline(h = 0, col = "purple")
```
```{r II-c}
ei = t.model$residuals
the.SWtest = shapiro.test(ei)
the.p.value <- the.SWtest$p.value
```
c. $p = `r round(the.p.value, 4)`$
```{r II-d, include=FALSE}
the.BFtest = leveneTest(ei~ Organ, data=t.data, center=median)
the.p.value = the.BFtest[[3]][1]
```
d. $p = `r round(the.p.value, 4)`$
```{r II-e}
# Calculate p-value for transformed dataset
transformed_model <- lm(Survival ~ Organ, data = t.data)
transformed_anova <- anova(transformed_model)
transformed_p_value <- transformed_anova$"Pr(>F)"[1]

# Calculate p-value for original dataset
original_model <- lm(Survival ~ Organ, data = cancer)
original_anova <- anova(original_model)
original_p_value <- original_anova$"Pr(>F)"[1]
```
e. The p-value for the original dataset is $`r format(round(original_p_value, 4), scientific = FALSE)`$, while the p-value for the transformed dataset is $`r format(round(transformed_p_value, 4), scientific = FALSE)`$. I believe the transformed dataset is more reliable because the original dataset violates the ANOVA assumptions, while the transformed dataset does not.

# III
a. There appears to be an interaction effect. When we move from lower to middle location, the change in number of average moths depends on the bait type. If the bait type is sugar, then we see an increase in average moths. If the bait type is chemical or scent, then we see a decrease in average moths. 
```{r III-a}
# Do interaction plot
the.plot.name <- "Interaction Plot of Moth Counts by Location and Bait Type"
interaction.plot(x.factor = trap$Location, trace.factor = trap$Bait,
                 response = trap$Moth, legend = TRUE,
                 xlab = "Location", ylab = "Number of Moths",
                 trace.label = "Bait Type", main = the.plot.name)
```
```{r III-bcd}
# Find means
the.means = find.means(trap,mean)

# Format the means in a nice table
the.location.means <- data.frame(Mean = round(the.means$A, 4))
the.bait.means <- data.frame(Mean = round(the.means$B, 4))
give.me.all.the.means <- round(the.means$AB, 4)
```
b. Here are the group means for location:
`r knitr::kable(the.location.means, format = "markdown")`
c. Here are the group means for bait:
`r knitr::kable(the.bait.means, format = "markdown")`
d. Here are the group means for all treatment levels:
`r knitr::kable(give.me.all.the.means, format = "markdown")`
e. Yes, the average number of moths trapped is different for each location. In part c, we get a different average number of moths trapped as we change location.

# IV
a. There seems to be an interaction effect between food type and food amount. When we decrease the amount of food, the decrease of weight change appears to be larder with beef and pork compared to cereal. 
```{r IV-a}
# Do interaction plot
the.plot.name = "Interaction Plot of Weight Change by Food Amount and Type"
interaction.plot(x.factor = rat$Amount, trace.factor = rat$Type,
                 response = rat$Weight, legend = TRUE,
                 xlab = "Food Amount", ylab = "Weight Change",
                 trace.label = " Food Type", main = the.plot.name)
```
```{r IV-bcd}
# Find means
the.means = find.means(rat,mean)

# Format the means in a nice table
the.amount.means <- data.frame(Mean = round(the.means$A, 4))
the.weight.means <- data.frame(Mean = round(the.means$B, 4))
give.me.all.the.means <- round(the.means$AB, 4)
```
b. Here are the group means for weight:
`r knitr::kable(the.weight.means, format = "markdown")`
c. Here are the group means for amount:
`r knitr::kable(the.amount.means, format = "markdown")`
d. Here are the group means for all treatment levels:
`r knitr::kable(give.me.all.the.means, format = "markdown")`
e. I believe the weight gain is different for the type of food. The average weight change is 84.9 for cereal compared to 89.6 for beef.

# Appendix
```{r appendix, include=TRUE, echo=FALSE, results="asis"}
# Get all the labels
all_labels <- knitr::all_labels()

# Print out code along with labels
for (label in all_labels) {
  if (label == "setup" || label == "appendix") {
    next
  }

  code <- knitr::knit_code$get(label)

  cat("##", label, "\n")
  cat("```r \n")
  cat(code, sep = "\n")
  cat("```\n")
}
```